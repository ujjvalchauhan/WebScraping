{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This project is to build a web application that scrapes various websites for data related to the Mission to Mars and displays the information in a single HTML page."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### For initial scraping following libraries are used:\n",
    "**BeautifulSoup**<br>\n",
    "it is a Python library for pulling data out of HTML and XML files. It works with any parser to provide idiomatic ways of navigating, searching, and modifying the parse tree.\n",
    "<br>\n",
    "**Pandas**<br>\n",
    "this python's data analysis library can be used with BeautifulSoup for web scraping. BeautifulSoup can pass the findings to pandas. Pandas can use its read_html function to read the HTML table data into a dataframe, which can be converted to JSON format.\n",
    "<br>\n",
    "**Requests**<br>\n",
    "it is a Python library that is used to send HTTP requests, add headers, form data, multiplart files and parameters with simple Python dictionaries, and access the response data in the same way.\n",
    "<br>\n",
    "**Splinter**<br>\n",
    "it is an open source tool for testing web applications using Python. it lets you automate browser actions, such as visting URLs and interacting with their items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Dependencies\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "# import Browser class from splinter\n",
    "from splinter import Browser\n",
    "\n",
    "# In order to use Google Chrome with Splinter, \n",
    "# Setting up Chrome WebDriver - Chrome WebDriver is provided by Selenium2. To use it, => pip install selenium\n",
    "# Download \"ChromeDriver server for win\" extract the zip file and add .exe file to the path.\n",
    "# Create Browser instance\n",
    "executable_path = {'executable_path': 'chromedriver.exe'}\n",
    "browser = Browser('chrome', **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NASA Mars News\n",
    "Scraping the NASA Mars News site and collecting the latest News Title and Paragraph text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:- on why use splinter over requests library in this case:**<br>\n",
    "<br>\n",
    "When a browser wants to access a webpage, it sends a request to the server on which the files that make up the webpage are located. The server then sends a response consisting of the page's source code back to the browser. The browser then interprets the HTML, CSS etc, in the source code, allows any Javascript to run, and displays the page.<br>\n",
    "<br>\n",
    "NASA Mars News site has a lot of Javascript code. When a Python library such as \"urllib\" or \"requests\" sends a request to a server, it receives the source code of the webpage, just like a browser does. However, Python cannot run Javascript and allow it to create the elements that hold the content that you need to scrape; the most it can do is parse the source code. In a situation like this, one in which you have to scrape content loaded dynamically by Javascript, content that is not present in the source code of the page, the Python module splinter comes in handy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL of NASA Mars News site\n",
    "nasa_news_url = 'https://mars.nasa.gov/news/'\n",
    "\n",
    "# Navigating with the browser.visit method of Splinter\n",
    "browser.visit(nasa_news_url)\n",
    "\n",
    "# Create BeautifulSoup object; parse with 'html.parser'\n",
    "html_nasa = browser.html\n",
    "soup = bs(html_nasa, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_title = soup.find(\"div\", class_=\"content_title\").text\n",
    "news_p = soup.find(\"div\", class_=\"article_teaser_body\").text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "News Title: NASA to Host Media Call on Next Mars Landing Site\n",
      "News Paragraph: NASA will host a media teleconference at 9 a.m. PST (noon EST) Monday, Nov. 19, to provide details about the Mars 2020 roverâ€™s landing site on the Red Planet.\n"
     ]
    }
   ],
   "source": [
    "print(f'News Title: {news_title}')\n",
    "print(f'News Paragraph: {news_p}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JPL Mars Space Images - Featured Image\n",
    "Scraping the JPL Featured Space Images website to get the image url for the current Featured Mars Image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL of JPL Mars Space Images site\n",
    "jpl_base_url = 'https://www.jpl.nasa.gov'\n",
    "jpl_mars_url = 'https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars'\n",
    "\n",
    "# Navigating with the browser.visit method of Splinter\n",
    "browser.visit(jpl_mars_url)\n",
    "\n",
    "# Create BeautifulSoup object; parse with 'html.parser'\n",
    "html_jpl = browser.html\n",
    "soup = bs(html_jpl, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Splinter - find_by_xpath method to find and click on the full size featured Mars image\n",
    "\n",
    "img_xpath = '//*[@id=\"page\"]/section[3]/div/ul/li[1]/a'\n",
    "\n",
    "# Finding the full size image by xpath\n",
    "find_img = browser.find_by_xpath(img_xpath)\n",
    "image = find_img[0]\n",
    "image.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<a class=\"button fancybox\" data-description=\"This image from NASA's Curiosity Mars rover shows Curiosity at the 'Rocknest' site where the rover scooped up samples of windblown dust and sand.\" data-fancybox-group=\"images\" data-fancybox-href=\"/spaceimages/images/mediumsize/PIA16919_ip.jpg\" data-link=\"/spaceimages/details.php?id=PIA16919\" data-title=\"Billion-Pixel View From Curiosity at Rock Nest, Raw Color\" id=\"full_image\">\n",
      "\t\t\t\t\tFULL IMAGE\n",
      "\t\t\t\t  </a>\n",
      "featured_image_url = https://www.jpl.nasa.gov/spaceimages/images/mediumsize/PIA16919_ip.jpg\n"
     ]
    }
   ],
   "source": [
    "# Using BeautifulSoup to get the url of full size featured Mars image\n",
    "link = soup.find('a',class_=\"fancybox\")\n",
    "print(link)\n",
    "featured_image_url = jpl_base_url + link['data-fancybox-href']\n",
    "print(f\"featured_image_url = {featured_image_url}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mars Weather\n",
    "Scraping Mars Weather twitter account and scraping the latest Mars weather tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL of Mars weather twitter account\n",
    "twitter_mars_url = 'https://twitter.com/marswxreport?lang=en'\n",
    "\n",
    "# Navigating with the browser.visit method of Splinter\n",
    "browser.visit(twitter_mars_url)\n",
    "\n",
    "# Create BeautifulSoup object; parse with 'html.parser'\n",
    "html_twitter = browser.html\n",
    "soup = bs(html_twitter, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mars Weather = Sol 2230 (2018-11-14), high -5C/23F, low -72C/-97F, pressure at 8.59 hPa, daylight 06:22-18:39\n"
     ]
    }
   ],
   "source": [
    "mars_weather = soup.find(\"p\", class_=\"TweetTextSize TweetTextSize--normal js-tweet-text tweet-text\").text\n",
    "print(f\"Mars Weather = {mars_weather}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mars Facts\n",
    "Scraping the Mars Facts webpage using Pandas to scrape the table containing facts about the planet including Diameter, Mass, etc. and using Pandas to convert the data to a HTML table string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL of Mars Facts webpage\n",
    "mars_facts_url = 'https://space-facts.com/mars/'\n",
    "\n",
    "# Navigating with the browser.visit method of Splinter\n",
    "browser.visit(mars_facts_url)\n",
    "\n",
    "# Creating BeautifulSoup object; parse with 'html.parser'\n",
    "html_marsfacts = browser.html\n",
    "soup = bs(html_marsfacts, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Description</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Equatorial Diameter:</th>\n",
       "      <td>6,792 km</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Polar Diameter:</th>\n",
       "      <td>6,752 km</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mass:</th>\n",
       "      <td>6.42 x 10^23 kg (10.7% Earth)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Moons:</th>\n",
       "      <td>2 (Phobos &amp; Deimos)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Orbit Distance:</th>\n",
       "      <td>227,943,824 km (1.52 AU)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Value\n",
       "Description                                        \n",
       "Equatorial Diameter:                       6,792 km\n",
       "Polar Diameter:                            6,752 km\n",
       "Mass:                 6.42 x 10^23 kg (10.7% Earth)\n",
       "Moons:                          2 (Phobos & Deimos)\n",
       "Orbit Distance:            227,943,824 km (1.52 AU)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the read_html function to automatically scrape any tabular data from a page.\n",
    "tables = pd.read_html(mars_facts_url)\n",
    "mars_facts_df = tables[0]\n",
    "mars_facts_df.columns = [\"Description\", \"Value\"]\n",
    "mars_facts_df.set_index(\"Description\", inplace=True)\n",
    "mars_facts_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<table border=\"1\" class=\"dataframe\">\\n  <thead>\\n    <tr style=\"text-align: right;\">\\n      <th></th>\\n      <th>Value</th>\\n    </tr>\\n    <tr>\\n      <th>Description</th>\\n      <th></th>\\n    </tr>\\n  </thead>\\n  <tbody>\\n    <tr>\\n      <th>Equatorial Diameter:</th>\\n      <td>6,792 km</td>\\n    </tr>\\n    <tr>\\n      <th>Polar Diameter:</th>\\n      <td>6,752 km</td>\\n    </tr>\\n    <tr>\\n      <th>Mass:</th>\\n      <td>6.42 x 10^23 kg (10.7% Earth)</td>\\n    </tr>\\n    <tr>\\n      <th>Moons:</th>\\n      <td>2 (Phobos &amp; Deimos)</td>\\n    </tr>\\n    <tr>\\n      <th>Orbit Distance:</th>\\n      <td>227,943,824 km (1.52 AU)</td>\\n    </tr>\\n    <tr>\\n      <th>Orbit Period:</th>\\n      <td>687 days (1.9 years)</td>\\n    </tr>\\n    <tr>\\n      <th>Surface Temperature:</th>\\n      <td>-153 to 20 Â°C</td>\\n    </tr>\\n    <tr>\\n      <th>First Record:</th>\\n      <td>2nd millennium BC</td>\\n    </tr>\\n    <tr>\\n      <th>Recorded By:</th>\\n      <td>Egyptian astronomers</td>\\n    </tr>\\n  </tbody>\\n</table>'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate HTML table from DataFrame\n",
    "html_table = mars_facts_df.to_html()\n",
    "html_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<table border=\"1\" class=\"dataframe\">  <thead>    <tr style=\"text-align: right;\">      <th></th>      <th>Value</th>    </tr>    <tr>      <th>Description</th>      <th></th>    </tr>  </thead>  <tbody>    <tr>      <th>Equatorial Diameter:</th>      <td>6,792 km</td>    </tr>    <tr>      <th>Polar Diameter:</th>      <td>6,752 km</td>    </tr>    <tr>      <th>Mass:</th>      <td>6.42 x 10^23 kg (10.7% Earth)</td>    </tr>    <tr>      <th>Moons:</th>      <td>2 (Phobos &amp; Deimos)</td>    </tr>    <tr>      <th>Orbit Distance:</th>      <td>227,943,824 km (1.52 AU)</td>    </tr>    <tr>      <th>Orbit Period:</th>      <td>687 days (1.9 years)</td>    </tr>    <tr>      <th>Surface Temperature:</th>      <td>-153 to 20 Â°C</td>    </tr>    <tr>      <th>First Record:</th>      <td>2nd millennium BC</td>    </tr>    <tr>      <th>Recorded By:</th>      <td>Egyptian astronomers</td>    </tr>  </tbody></table>'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean the table by stripping unwanted newlines\n",
    "html_table.replace('\\n', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the table\n",
    "mars_facts_df.to_html('mars_facts_table.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mars Hemispheres\n",
    "Scraping the USGS Astrogeology site to obtain high resolution images for each of Mars' hemispheres.<br>\n",
    "\n",
    "(click each of the links to the hemispheres in order to find the image url to the full resolution image.\n",
    "\n",
    "Save both the image url string for the full resolution hemisphere image, and the Hemisphere title containing the hemisphere name. Use a Python dictionary to store the data using the keys img_url and title.\n",
    "\n",
    "Append the dictionary with the image url string and the hemisphere title to a list. This list will contain one dictionary for each hemisphere.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL of USGS Astrogeology site\n",
    "usgs_url = 'https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars'\n",
    "\n",
    "# Navigating with the browser.visit method of Splinter\n",
    "browser.visit(usgs_url)\n",
    "\n",
    "# Creating BeautifulSoup object; parse with 'html.parser'\n",
    "usgs_html = browser.html\n",
    "soup = bs(usgs_html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "usgs_base_url = 'https://astrogeology.usgs.gov'\n",
    "\n",
    "results = soup.find_all(\"div\", class_=\"description\")\n",
    "\n",
    "hemisphere_image_urls = []\n",
    "\n",
    "for result in results:\n",
    "    title = result.find(\"h3\").text\n",
    "    title = ' '.join(title.split(' ')[:-1])\n",
    "    \n",
    "    button = result.find(\"a\", class_=\"itemLink product-item\")['href']\n",
    "    url = usgs_base_url + button\n",
    "    \n",
    "    # Using browser.visit method to navigate to each link\n",
    "    browser.visit(url)\n",
    "    \n",
    "    # Creating BeautifulSoup object for the navigated page; parse with 'html.parser'\n",
    "    link_html = browser.html\n",
    "    soup = bs(link_html, 'html.parser')\n",
    "    \n",
    "    # Finding the url for the full resolution hemisphere image on the navigated page\n",
    "    link = soup.find(\"img\", class_=\"wide-image\")[\"src\"]\n",
    "    \n",
    "    # Creating a dictionary to store title and url for each hemisphere\n",
    "    dict = {'title':title, 'img_url':usgs_base_url + link}\n",
    "    \n",
    "    # Appending the dictionaries to a list\n",
    "    hemisphere_image_urls.append(dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'Cerberus Hemisphere',\n",
       "  'img_url': 'https://astrogeology.usgs.gov/cache/images/cfa62af2557222a02478f1fcd781d445_cerberus_enhanced.tif_full.jpg'},\n",
       " {'title': 'Schiaparelli Hemisphere',\n",
       "  'img_url': 'https://astrogeology.usgs.gov/cache/images/3cdd1cbf5e0813bba925c9030d13b62e_schiaparelli_enhanced.tif_full.jpg'},\n",
       " {'title': 'Syrtis Major Hemisphere',\n",
       "  'img_url': 'https://astrogeology.usgs.gov/cache/images/ae209b4e408bb6c3e67b6af38168cf28_syrtis_major_enhanced.tif_full.jpg'},\n",
       " {'title': 'Valles Marineris Hemisphere',\n",
       "  'img_url': 'https://astrogeology.usgs.gov/cache/images/7cf2da4bf549ed01c17f206327be4db7_valles_marineris_enhanced.tif_full.jpg'}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hemisphere_image_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
